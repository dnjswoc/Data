import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from sklearn.preprocessing import MinMaxScaler


# ğŸ“Œ 1ï¸âƒ£ ì„œìš¸ í–‰ì •ë™ GeoJSON íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
geojson_path = "ì„œìš¸ì‹œ_í–‰ì •ë™_ê²½ê³„.geojson"
gdf_admin = gpd.read_file(geojson_path)


# ğŸ“Œ ì¢Œí‘œê³„ í™•ì¸
print(f"í˜„ì¬ ì¢Œí‘œê³„: {gdf_admin.crs}")

# ğŸ“Œ EPSG:4326ìœ¼ë¡œ ë³€í™˜
if gdf_admin.crs != "EPSG:4326":
    gdf_admin = gdf_admin.to_crs("EPSG:4326")

# ğŸ“Œ ë³€í™˜ëœ ë°ì´í„° í™•ì¸
print(gdf_admin.head())

# ğŸ“Œ 2ï¸âƒ£ ë²„ìŠ¤ & ì§€í•˜ì²  ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (XLSX íŒŒì¼)
bus_df = pd.read_excel("ì„œìš¸ì‹œ_ë²„ìŠ¤ì •ë¥˜ì¥.xlsx", sheet_name=0, usecols=["Xì¢Œí‘œ", "Yì¢Œí‘œ"])
subway_df = pd.read_csv("ì„œìš¸ì‹œ_ì§€í•˜ì² ì—­.csv", usecols=["í™˜ìŠ¹ì—­Xì¢Œí‘œ", "í™˜ìŠ¹ì—­Yì¢Œí‘œ"])

# ğŸ“Œ 3ï¸âƒ£ ì¢Œí‘œ ë°ì´í„°ë¥¼ GeoDataFrameìœ¼ë¡œ ë³€í™˜
bus_gdf = gpd.GeoDataFrame(bus_df, geometry=gpd.points_from_xy(bus_df["Xì¢Œí‘œ"], bus_df["Yì¢Œí‘œ"]), crs="EPSG:4326")
subway_gdf = gpd.GeoDataFrame(subway_df, geometry=gpd.points_from_xy(subway_df["í™˜ìŠ¹ì—­Xì¢Œí‘œ"], subway_df["í™˜ìŠ¹ì—­Yì¢Œí‘œ"]), crs="EPSG:4326")

# ğŸ“Œ 4ï¸âƒ£ ì¢Œí‘œë¥¼ í–‰ì •ë™ê³¼ ë§¤ì¹­ (Spatial Join)
bus_gdf = gpd.sjoin(bus_gdf, gdf_admin, how="left", predicate="within")
subway_gdf = gpd.sjoin(subway_gdf, gdf_admin, how="left", predicate="within")

print(bus_gdf.head())

# ğŸ“Œ 5ï¸âƒ£ í–‰ì •ë™ë³„ ê°œìˆ˜ ì§‘ê³„
bus_count = bus_gdf.groupby("ADM_CD").size().reset_index(name="ë²„ìŠ¤ ì •ë¥˜ì¥ ìˆ˜")
subway_count = subway_gdf.groupby("ADM_CD").size().reset_index(name="ì§€í•˜ì² ì—­ ìˆ˜")

# ğŸ“Œ 6ï¸âƒ£ ë²„ìŠ¤ + ì§€í•˜ì²  ë°ì´í„°ë¥¼ ë³‘í•© í›„ "ëŒ€ì¤‘êµí†µ ì ìˆ˜" ê³„ì‚°
df_transport = pd.merge(bus_count, subway_count, on="ADM_CD", how="outer").fillna(0)
df_transport["ì´ ëŒ€ì¤‘êµí†µ ìˆ˜"] = df_transport["ë²„ìŠ¤ ì •ë¥˜ì¥ ìˆ˜"] + df_transport["ì§€í•˜ì² ì—­ ìˆ˜"]

print(df_transport)


# ğŸ“Œ 1ï¸âƒ£ í–‰ì •ë™ ì½”ë“œ(ADM_CD)ì™€ í–‰ì •ë™ ì´ë¦„(ADM_NM) ë§¤í•‘ ë°ì´í„° ìƒì„±
adm_mapping = gdf_admin[["ADM_CD", "ADM_NM"]].drop_duplicates()

# ğŸ“Œ 2ï¸âƒ£ df_transportì— ADM_NM ì¶”ê°€ (ADM_CD ê¸°ì¤€ ë³‘í•©)
df_transport = df_transport.merge(adm_mapping, on="ADM_CD", how="left")

df_transport["ì§€í•˜ì² ì—­ ìˆ˜"] = pd.to_numeric(df_transport["ì§€í•˜ì² ì—­ ìˆ˜"]).astype(int)
df_transport["ì´ ëŒ€ì¤‘êµí†µ ìˆ˜"] = pd.to_numeric(df_transport["ì´ ëŒ€ì¤‘êµí†µ ìˆ˜"]).astype(int)
# ğŸ“Œ 3ï¸âƒ£ ê²°ê³¼ í™•ì¸
print(df_transport.head())

df_census = pd.read_excel("ì„¼ì„œìŠ¤ ê³µê°„ì •ë³´ ì§€ì—­ ì½”ë“œ.xlsx", sheet_name=0)
print(df_census.info())
# ğŸ“Œ 1ï¸âƒ£ ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ëª…ì„ ìˆ˜ë™ ì„¤ì •
# df_census.columns = ["ì‹œë„ì½”ë“œ", "ì‹œêµ°êµ¬ì½”ë“œ", "ì‹œêµ°êµ¬ëª…ì¹­", "ìë©´ë™ì½”ë“œ", "ìë©´ë™ëª…ì¹­"]
# df_census = df_census[["ì‹œêµ°êµ¬ì½”ë“œ", "ìë©´ë™ì½”ë“œ", "ì‹œêµ°êµ¬ëª…ì¹­", "ìë©´ë™ëª…ì¹­"]].drop_duplicates()

# ğŸ“Œ 2ï¸âƒ£ df_transportì˜ ADM_CDì—ì„œ ì‹œêµ°êµ¬ì½”ë“œ, ìë©´ë™ì½”ë“œ ì¶”ì¶œ
df_transport["ì‹œêµ°êµ¬ì½”ë“œ"] = df_transport["ADM_CD"].astype(str).str[2:5]
df_transport["ìë©´ë™ì½”ë“œ"] = df_transport["ADM_CD"].astype(str).str[5:]
df_transport["ì‹œêµ°êµ¬ì½”ë“œ"] = pd.to_numeric(df_transport["ì‹œêµ°êµ¬ì½”ë“œ"])
df_transport["ìë©´ë™ì½”ë“œ"] = pd.to_numeric(df_transport["ìë©´ë™ì½”ë“œ"])

# ğŸ“Œ 3ï¸âƒ£ df_transportì™€ df_censusë¥¼ ì‹œêµ°êµ¬ì½”ë“œ, ìë©´ë™ì½”ë“œ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
df_transport = df_transport.merge(df_census, on=["ì‹œêµ°êµ¬ì½”ë“œ", "ìë©´ë™ì½”ë“œ"], how="left")

# ì„ íƒí•  ì¹¼ëŸ¼ ë¦¬ìŠ¤íŠ¸ (ì›í•˜ëŠ” ì¹¼ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½)
selected_columns = ['ì‹œë„ëª…ì¹­', 'ì‹œêµ°êµ¬ëª…ì¹­', 'ìë©´ë™ëª…ì¹­', 'ë²„ìŠ¤ ì •ë¥˜ì¥ ìˆ˜', 'ì§€í•˜ì² ì—­ ìˆ˜', 'ì´ ëŒ€ì¤‘êµí†µ ìˆ˜']  # ì›í•˜ëŠ” ì¹¼ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •

# ì„ íƒí•œ ì¹¼ëŸ¼ë§Œ ì¶”ì¶œ
df_selected = df_transport[selected_columns]

# ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥
output_path = "ì„œìš¸íŠ¹ë³„ì‹œ_ëŒ€ì¤‘êµí†µ_ìˆ˜_ì—…ë°ì´íŠ¸.csv"
df_selected.to_csv(output_path, index=False, encoding="utf-8-sig")

print(f"ì„ íƒí•œ ì¹¼ëŸ¼ë§Œ í¬í•¨ëœ CSV íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")